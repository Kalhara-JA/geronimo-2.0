The user requests a document vectorization pipeline in Ballerina that retrieves multiple files from Google Drive, processes them, and stores vector embeddings in PostgreSQL. The pipeline needs to handle Google Drive authentication and file retrieval using googleapis.drive module, extract document content to plain text and save it in markdown files in a new folder. The pipeline should include text chunking with configurable size and overlap (500 characters default, 100-character overlap) with optional sentence-based segmentation, metadata enrichment capturing filename, type, createdTime, and source URL, vector embedding generation using OpenAI's embeddings API with bearer token authentication, and PostgreSQL integration using pgvector extension for storing chunk metadata and vectors (1536-dimensional). The implementation should include comprehensive error handling and logging using Ballerina's log module, be modular, use typed records, and implement reusable functions following best practices. Additionally, the code should include necessary comments for all files.